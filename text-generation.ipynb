{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":943773,"sourceType":"datasetVersion","datasetId":511492}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport csv\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW\n\nclass StoriesDataset(Dataset):\n    def __init__(self, dataset_path):\n        super().__init__()\n        self.story_list = []\n        self.end_of_text_token = \"<|endoftext|>\"\n\n        # Increase the CSV field size limit\n        import sys\n        csv.field_size_limit(sys.maxsize)\n\n        with open(dataset_path, encoding=\"utf-8\") as csv_file:\n            csv_reader = csv.reader(csv_file)\n            next(csv_reader)  # Skip header\n            for row in csv_reader:\n                story = f\"STORY: {row[1]} {self.end_of_text_token}\"\n                self.story_list.append(story)\n\n    def __len__(self):\n        return len(self.story_list)\n\n    def __getitem__(self, idx):\n        return self.story_list[idx]\n\n\n# Initialize tokenizer and model\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\ntokenizer.pad_token = tokenizer.eos_token\nmodel = GPT2LMHeadModel.from_pretrained(\"gpt2\")\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = model.to(device)\n\n# Load the dataset\ndata_path = \"/kaggle/input/1002-short-stories-from-project-guttenberg/stories.csv\"  # Update with your file path\ndataset = StoriesDataset(data_path)\ndata_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n\n# Optimizer\noptimizer = AdamW(model.parameters(), lr=5e-5)\n\n# Fine-tuning\nEPOCHS = 10\nSAVE_PATH = \"gpt2_finetuned.pt\"\n\nmodel.train()\nfor epoch in range(EPOCHS):\n    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n    for batch_idx, batch in enumerate(data_loader):\n        inputs = tokenizer(batch, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n        inputs = {key: value.to(device) for key, value in inputs.items()}\n\n        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n        loss = outputs.loss\n\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        if (batch_idx + 1) % 10 == 0:\n            print(f\"Batch {batch_idx + 1}: Loss = {loss.item():.4f}\")\n\n    # Save checkpoint\n    torch.save(model.state_dict(), SAVE_PATH)\n\n# Generate text\ndef generate_story(prompt, max_length=200):\n    model.eval()\n    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n\n    with torch.no_grad():\n        output = model.generate(\n            input_ids,\n            max_length=max_length,\n            num_beams=5,\n            temperature=0.7,\n            no_repeat_ngram_size=2,\n            early_stopping=True\n        )\n    return tokenizer.decode(output[0], skip_special_tokens=True)\n\n# Example usage\nstart_prompt = \"Once upon a time in a dystopian world,\"\ngenerated_story = generate_story(start_prompt)\nprint(\"Generated Story:\")\nprint(generated_story)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T01:03:22.860768Z","iopub.execute_input":"2024-12-04T01:03:22.861489Z","iopub.status.idle":"2024-12-04T01:57:57.306760Z","shell.execute_reply.started":"2024-12-04T01:03:22.861455Z","shell.execute_reply":"2024-12-04T01:57:57.305826Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\nBatch 10: Loss = 3.4116\nBatch 20: Loss = 2.5131\nBatch 30: Loss = 2.4119\nBatch 40: Loss = 2.8294\nBatch 50: Loss = 1.9235\nBatch 60: Loss = 2.6701\nBatch 70: Loss = 2.4486\nBatch 80: Loss = 2.3809\nBatch 90: Loss = 2.3415\nBatch 100: Loss = 2.1501\nBatch 110: Loss = 2.3296\nBatch 120: Loss = 2.5440\nBatch 130: Loss = 2.1042\nBatch 140: Loss = 2.1422\nBatch 150: Loss = 2.6855\nBatch 160: Loss = 2.4946\nBatch 170: Loss = 2.4416\nBatch 180: Loss = 1.9870\nBatch 190: Loss = 1.9298\nBatch 200: Loss = 2.1563\nBatch 210: Loss = 1.5314\nBatch 220: Loss = 2.2553\nBatch 230: Loss = 2.5210\nBatch 240: Loss = 2.2991\nBatch 250: Loss = 2.7824\nEpoch 2/10\nBatch 10: Loss = 1.9781\nBatch 20: Loss = 1.8925\nBatch 30: Loss = 2.3991\nBatch 40: Loss = 2.2373\nBatch 50: Loss = 2.0490\nBatch 60: Loss = 1.7992\nBatch 70: Loss = 1.8702\nBatch 80: Loss = 2.3987\nBatch 90: Loss = 2.4035\nBatch 100: Loss = 2.1592\nBatch 110: Loss = 3.1247\nBatch 120: Loss = 1.7489\nBatch 130: Loss = 2.1955\nBatch 140: Loss = 2.1670\nBatch 150: Loss = 2.3179\nBatch 160: Loss = 1.9818\nBatch 170: Loss = 1.7887\nBatch 180: Loss = 2.0455\nBatch 190: Loss = 2.2546\nBatch 200: Loss = 2.4359\nBatch 210: Loss = 2.3513\nBatch 220: Loss = 2.3963\nBatch 230: Loss = 2.7631\nBatch 240: Loss = 1.6737\nBatch 250: Loss = 2.4302\nEpoch 3/10\nBatch 10: Loss = 2.1315\nBatch 20: Loss = 1.8310\nBatch 30: Loss = 2.8316\nBatch 40: Loss = 1.9471\nBatch 50: Loss = 1.9860\nBatch 60: Loss = 2.0617\nBatch 70: Loss = 2.3642\nBatch 80: Loss = 2.2792\nBatch 90: Loss = 2.1314\nBatch 100: Loss = 2.3875\nBatch 110: Loss = 1.3914\nBatch 120: Loss = 2.1748\nBatch 130: Loss = 1.5948\nBatch 140: Loss = 2.2161\nBatch 150: Loss = 2.2293\nBatch 160: Loss = 1.6710\nBatch 170: Loss = 2.4223\nBatch 180: Loss = 2.4788\nBatch 190: Loss = 2.4086\nBatch 200: Loss = 2.2143\nBatch 210: Loss = 1.8642\nBatch 220: Loss = 2.1134\nBatch 230: Loss = 2.0650\nBatch 240: Loss = 2.3171\nBatch 250: Loss = 1.7487\nEpoch 4/10\nBatch 10: Loss = 2.0188\nBatch 20: Loss = 1.9531\nBatch 30: Loss = 1.5864\nBatch 40: Loss = 2.5907\nBatch 50: Loss = 2.0207\nBatch 60: Loss = 2.0326\nBatch 70: Loss = 2.1473\nBatch 80: Loss = 1.6510\nBatch 90: Loss = 2.0209\nBatch 100: Loss = 1.7607\nBatch 110: Loss = 1.8564\nBatch 120: Loss = 1.3562\nBatch 130: Loss = 1.9877\nBatch 140: Loss = 1.6777\nBatch 150: Loss = 2.4115\nBatch 160: Loss = 1.8341\nBatch 170: Loss = 2.0057\nBatch 180: Loss = 1.5756\nBatch 190: Loss = 1.2570\nBatch 200: Loss = 1.8479\nBatch 210: Loss = 2.1065\nBatch 220: Loss = 1.3488\nBatch 230: Loss = 1.9992\nBatch 240: Loss = 2.0464\nBatch 250: Loss = 2.0289\nEpoch 5/10\nBatch 10: Loss = 1.7931\nBatch 20: Loss = 2.0126\nBatch 30: Loss = 2.1661\nBatch 40: Loss = 1.5507\nBatch 50: Loss = 1.8882\nBatch 60: Loss = 1.1004\nBatch 70: Loss = 2.1224\nBatch 80: Loss = 0.8700\nBatch 90: Loss = 1.6712\nBatch 100: Loss = 1.2668\nBatch 110: Loss = 1.6680\nBatch 120: Loss = 2.1348\nBatch 130: Loss = 2.3766\nBatch 140: Loss = 2.3168\nBatch 150: Loss = 1.6465\nBatch 160: Loss = 2.3485\nBatch 170: Loss = 1.8801\nBatch 180: Loss = 1.8366\nBatch 190: Loss = 1.7358\nBatch 200: Loss = 1.5536\nBatch 210: Loss = 2.3986\nBatch 220: Loss = 1.7668\nBatch 230: Loss = 1.8179\nBatch 240: Loss = 1.8674\nBatch 250: Loss = 1.9243\nEpoch 6/10\nBatch 10: Loss = 1.7309\nBatch 20: Loss = 1.7467\nBatch 30: Loss = 2.1294\nBatch 40: Loss = 1.4797\nBatch 50: Loss = 1.4448\nBatch 60: Loss = 1.9612\nBatch 70: Loss = 2.2387\nBatch 80: Loss = 1.6889\nBatch 90: Loss = 1.9167\nBatch 100: Loss = 1.4539\nBatch 110: Loss = 1.9896\nBatch 120: Loss = 1.8133\nBatch 130: Loss = 1.6233\nBatch 140: Loss = 1.5264\nBatch 150: Loss = 1.5084\nBatch 160: Loss = 1.9516\nBatch 170: Loss = 1.4882\nBatch 180: Loss = 1.9229\nBatch 190: Loss = 1.9504\nBatch 200: Loss = 1.8323\nBatch 210: Loss = 1.6754\nBatch 220: Loss = 2.2581\nBatch 230: Loss = 1.9231\nBatch 240: Loss = 1.8766\nBatch 250: Loss = 2.3159\nEpoch 7/10\nBatch 10: Loss = 1.8074\nBatch 20: Loss = 1.6643\nBatch 30: Loss = 1.4756\nBatch 40: Loss = 1.3760\nBatch 50: Loss = 2.1083\nBatch 60: Loss = 2.1226\nBatch 70: Loss = 2.0046\nBatch 80: Loss = 1.2912\nBatch 90: Loss = 2.0879\nBatch 100: Loss = 1.7677\nBatch 110: Loss = 1.6060\nBatch 120: Loss = 1.8129\nBatch 130: Loss = 1.9428\nBatch 140: Loss = 1.1759\nBatch 150: Loss = 1.6031\nBatch 160: Loss = 1.8798\nBatch 170: Loss = 2.2946\nBatch 180: Loss = 1.4649\nBatch 190: Loss = 1.8636\nBatch 200: Loss = 1.6243\nBatch 210: Loss = 1.8838\nBatch 220: Loss = 1.2675\nBatch 230: Loss = 2.0497\nBatch 240: Loss = 1.5337\nBatch 250: Loss = 1.9838\nEpoch 8/10\nBatch 10: Loss = 1.6647\nBatch 20: Loss = 1.1557\nBatch 30: Loss = 1.7657\nBatch 40: Loss = 1.4659\nBatch 50: Loss = 1.4173\nBatch 60: Loss = 2.0851\nBatch 70: Loss = 1.1558\nBatch 80: Loss = 1.5728\nBatch 90: Loss = 1.6111\nBatch 100: Loss = 1.9089\nBatch 110: Loss = 1.5098\nBatch 120: Loss = 1.5992\nBatch 130: Loss = 1.4229\nBatch 140: Loss = 1.7707\nBatch 150: Loss = 1.5775\nBatch 160: Loss = 1.7430\nBatch 170: Loss = 1.6972\nBatch 180: Loss = 1.8076\nBatch 190: Loss = 1.4517\nBatch 200: Loss = 1.8451\nBatch 210: Loss = 1.5579\nBatch 220: Loss = 2.1561\nBatch 230: Loss = 2.3963\nBatch 240: Loss = 1.6722\nBatch 250: Loss = 1.5970\nEpoch 9/10\nBatch 10: Loss = 1.9655\nBatch 20: Loss = 1.9077\nBatch 30: Loss = 1.8313\nBatch 40: Loss = 1.3090\nBatch 50: Loss = 1.2552\nBatch 60: Loss = 1.9635\nBatch 70: Loss = 1.4045\nBatch 80: Loss = 1.6668\nBatch 90: Loss = 1.7052\nBatch 100: Loss = 1.5738\nBatch 110: Loss = 1.5286\nBatch 120: Loss = 2.2033\nBatch 130: Loss = 1.8729\nBatch 140: Loss = 1.3234\nBatch 150: Loss = 1.6743\nBatch 160: Loss = 1.8446\nBatch 170: Loss = 1.1958\nBatch 180: Loss = 1.6198\nBatch 190: Loss = 1.5019\nBatch 200: Loss = 1.3395\nBatch 210: Loss = 1.3425\nBatch 220: Loss = 1.5264\nBatch 230: Loss = 2.0938\nBatch 240: Loss = 1.2982\nBatch 250: Loss = 1.5165\nEpoch 10/10\nBatch 10: Loss = 1.7579\nBatch 20: Loss = 1.2253\nBatch 30: Loss = 0.9079\nBatch 40: Loss = 1.5230\nBatch 50: Loss = 1.3079\nBatch 60: Loss = 1.8931\nBatch 70: Loss = 1.5981\nBatch 80: Loss = 1.6411\nBatch 90: Loss = 1.3288\nBatch 100: Loss = 1.4389\nBatch 110: Loss = 1.1323\nBatch 120: Loss = 1.4733\nBatch 130: Loss = 1.4905\nBatch 140: Loss = 1.3826\nBatch 150: Loss = 1.0425\nBatch 160: Loss = 1.7678\nBatch 170: Loss = 1.4347\nBatch 180: Loss = 1.5915\nBatch 190: Loss = 1.5542\nBatch 200: Loss = 1.5495\nBatch 210: Loss = 1.6327\nBatch 220: Loss = 1.6167\nBatch 230: Loss = 1.6651\nBatch 240: Loss = 1.9152\nBatch 250: Loss = 1.5399\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Generated Story:\nOnce upon a time in a dystopian world, there was a man who was willing to sacrifice his own life for the betterment of mankind. And he did it with a smile on his face.\"\n\n\n\n“Well,” said the man, “it’s all right to say that. I mean, you know, I'm not going to go into much detail about it, but I want you to know that this is the first story I ever wrote, and I've never written a story before in which I said, \"I want to do this,\" and that was before I started doing this story. So I just wanted to make sure you all understood that I was just trying to be as honest with you as I could be, so that you could understand what I meant by the word 'humor' in that particular sentence.\n\n   So here it is, here we go again, with all of the facts and figures in the story and with the\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}