{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10091416,"sourceType":"datasetVersion","datasetId":6222747}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Required Libraries\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import nn, optim\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem.isri import ISRIStemmer\nimport nltk\nimport numpy as np\nimport pandas as pd\n\nnltk.download('punkt')\nnltk.download('stopwords')\n\n# Load Dataset\ndataset = pd.read_csv('/kaggle/input/datasetdlarabic/aljazeera_data.csv')  # Update path if necessary\ndataset = dataset.dropna()  # Remove any null values\n\n# Preprocessing Pipeline\nclass TextPreprocessor:\n    def __init__(self):\n        self.stop_words = set(stopwords.words('arabic'))\n        self.stemmer = ISRIStemmer()  # Arabic-specific stemmer\n\n    def preprocess(self, text):\n        # Tokenization\n        tokens = word_tokenize(text)\n        # Remove stop words\n        tokens = [t for t in tokens if t not in self.stop_words]\n        # Stemming\n        tokens = [self.stemmer.stem(t) for t in tokens]\n        return tokens\n\npreprocessor = TextPreprocessor()\ndataset['Processed_Text'] = dataset['Text'].apply(preprocessor.preprocess)\n\n# Encoding Labels\nlabel_encoder = LabelEncoder()\ndataset['Encoded_Score'] = label_encoder.fit_transform(dataset['Score'])\n\n# Split Data\nX_train, X_test, y_train, y_test = train_test_split(\n    dataset['Processed_Text'], dataset['Encoded_Score'], test_size=0.2, random_state=42\n)\n\n# Dataset Class\nclass NLPDataset(Dataset):\n    def __init__(self, texts, labels, vocab=None):\n        self.texts = texts\n        self.labels = labels\n        self.vocab = vocab or self.build_vocab()\n\n    def build_vocab(self):\n        vocab = set(token for text in self.texts for token in text)\n        return {word: idx for idx, word in enumerate(vocab, start=1)}\n\n    def encode_text(self, text):\n        return [self.vocab[token] for token in text if token in self.vocab]\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        encoded_text = self.encode_text(self.texts.iloc[idx])\n        label = self.labels.iloc[idx]\n        return torch.tensor(encoded_text, dtype=torch.long), torch.tensor(label, dtype=torch.long)\n\ntrain_dataset = NLPDataset(X_train, y_train)\ntest_dataset = NLPDataset(X_test, y_test, vocab=train_dataset.vocab)\n\ndef collate_fn(batch):\n    texts, labels = zip(*batch)\n    max_len = max(len(text) for text in texts)\n    padded_texts = [torch.cat([text, torch.zeros(max_len - len(text))]) for text in texts]\n    return torch.stack(padded_texts), torch.tensor(labels)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n\n\n# Check for GPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# LSTM Model with GPU Support\nclass LSTMModel(nn.Module):\n    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n        super(LSTMModel, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim)\n        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n        self.fc = nn.Linear(hidden_dim * 2, output_dim)  # Multiply by 2 for bidirectional\n\n    def forward(self, x):\n        x = self.embedding(x.long())\n        _, (hidden, _) = self.lstm(x)\n        # Combine forward and backward hidden states\n        hidden = torch.cat((hidden[-2], hidden[-1]), dim=1)\n        output = self.fc(hidden)\n        return output\n\n# Model Parameters\nvocab_size = len(train_dataset.vocab) + 1\nembed_dim = 128\nhidden_dim = 256\noutput_dim = len(label_encoder.classes_)\n\n# Instantiate Model and Move to Device\nmodel = LSTMModel(vocab_size, embed_dim, hidden_dim, output_dim).to(device)\n\n# Training Settings\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nepochs = 10\n\n# Training Loop with GPU Support\nfor epoch in range(epochs):\n    model.train()\n    total_loss = 0\n    for texts, labels in train_loader:\n        texts, labels = texts.to(device), labels.to(device)  # Move data to GPU\n        optimizer.zero_grad()\n        outputs = model(texts)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}\")\n\n# Evaluation Function with GPU Support\ndef evaluate_model(model, data_loader):\n    model.eval()\n    y_true, y_pred = [], []\n    with torch.no_grad():\n        for texts, labels in data_loader:\n            texts, labels = texts.to(device), labels.to(device)  # Move data to GPU\n            outputs = model(texts)\n            predicted = torch.argmax(outputs, dim=1)\n            y_true.extend(labels.cpu().tolist())  # Move back to CPU for metrics\n            y_pred.extend(predicted.cpu().tolist())  # Move back to CPU for metrics\n    return y_true, y_pred\n\n# Calculate Metrics\ny_train_true, y_train_pred = evaluate_model(model, train_loader)\ny_test_true, y_test_pred = evaluate_model(model, test_loader)\n\n# Training Metrics\ntrain_mse = mean_squared_error(y_train_true, y_train_pred)\ntrain_mae = mean_absolute_error(y_train_true, y_train_pred)\ntrain_r2 = r2_score(y_train_true, y_train_pred)\ntrain_acc = accuracy_score(y_train_true, y_train_pred)\n\n# Testing Metrics\ntest_mse = mean_squared_error(y_test_true, y_test_pred)\ntest_mae = mean_absolute_error(y_test_true, y_test_pred)\ntest_r2 = r2_score(y_test_true, y_test_pred)\ntest_acc = accuracy_score(y_test_true, y_test_pred)\n\n# Print Metrics\nprint(\"Training Metrics:\")\nprint(f\"MSE: {train_mse:.4f}, MAE: {train_mae:.4f}, R2: {train_r2:.4f}, Accuracy: {train_acc:.4f}\")\nprint(\"Testing Metrics:\")\nprint(f\"MSE: {test_mse:.4f}, MAE: {test_mae:.4f}, R2: {test_r2:.4f}, Accuracy: {test_acc:.4f}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T00:14:14.572653Z","iopub.execute_input":"2024-12-04T00:14:14.572968Z","iopub.status.idle":"2024-12-04T00:14:51.691883Z","shell.execute_reply.started":"2024-12-04T00:14:14.572941Z","shell.execute_reply":"2024-12-04T00:14:51.690984Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\nUsing device: cuda\nEpoch 1, Loss: 1.1123\nEpoch 2, Loss: 0.6933\nEpoch 3, Loss: 0.5175\nEpoch 4, Loss: 0.3984\nEpoch 5, Loss: 0.3169\nEpoch 6, Loss: 0.2243\nEpoch 7, Loss: 0.1607\nEpoch 8, Loss: 0.1113\nEpoch 9, Loss: 0.0952\nEpoch 10, Loss: 0.0657\nTraining Metrics:\nMSE: 0.7984, MAE: 0.0522, R2: 0.9684, Accuracy: 0.9929\nTesting Metrics:\nMSE: 5.4629, MAE: 0.6007, R2: 0.6410, Accuracy: 0.9081\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n\ndef calculate_bleu_score(y_true, y_pred, label_decoder):\n    \"\"\"\n    Calculate BLEU score for true and predicted labels.\n    Args:\n        y_true: List of true labels (integer or numeric encoded).\n        y_pred: List of predicted labels (integer or numeric encoded).\n        label_decoder: Function to decode integer labels to text labels.\n    Returns:\n        Average BLEU score and individual BLEU scores.\n    \"\"\"\n    references = []\n    candidates = []\n\n    for true, pred in zip(y_true, y_pred):\n        # Decode and tokenize true label\n        true_decoded = label_decoder(true)\n        if isinstance(true_decoded, str):\n            references.append([true_decoded.split()])\n        else:\n            raise ValueError(f\"Decoded reference is not a string: {true_decoded}\")\n\n        # Decode and tokenize predicted label\n        pred_decoded = label_decoder(pred)\n        if isinstance(pred_decoded, str):\n            candidates.append(pred_decoded.split())\n        else:\n            raise ValueError(f\"Decoded candidate is not a string: {pred_decoded}\")\n\n    # Calculate BLEU scores\n    individual_bleu_scores = [\n        sentence_bleu(reference, candidate, weights=(1.0, 0, 0, 0))  # Unigram BLEU\n        for reference, candidate in zip(references, candidates)\n    ]\n    average_bleu = corpus_bleu(references, candidates, weights=(1.0, 0, 0, 0))  # Unigram BLEU\n    return average_bleu, individual_bleu_scores\n\n# Label Decoder Function\ndef decode_label(encoded_label):\n    \"\"\"\n    Decode an integer-encoded label back to its original text representation.\n    Args:\n        encoded_label: Integer or float representation of the label.\n    Returns:\n        Decoded text label.\n    \"\"\"\n    if isinstance(encoded_label, (int, float)):\n        return f\"decoded_text_{int(encoded_label)}\"\n    return str(encoded_label)\n\n# Calculate BLEU scores for training and testing data\ntrain_bleu, train_individual_bleu_scores = calculate_bleu_score(y_train_true, y_train_pred, decode_label)\ntest_bleu, test_individual_bleu_scores = calculate_bleu_score(y_test_true, y_test_pred, decode_label)\n\n# Print Metrics\nprint(\"Training BLEU Score:\", train_bleu)\nprint(\"Testing BLEU Score:\", test_bleu)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T00:17:17.855937Z","iopub.execute_input":"2024-12-04T00:17:17.856554Z","iopub.status.idle":"2024-12-04T00:17:17.939258Z","shell.execute_reply.started":"2024-12-04T00:17:17.856522Z","shell.execute_reply":"2024-12-04T00:17:17.938401Z"}},"outputs":[{"name":"stdout","text":"Training BLEU Score: 0.9929266136162688\nTesting BLEU Score: 0.9081272084805654\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \nCorpus/Sentence contains 0 counts of 2-gram overlaps.\nBLEU scores might be undesirable; use SmoothingFunction().\n  warnings.warn(_msg)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}